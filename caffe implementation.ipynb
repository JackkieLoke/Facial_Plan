{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import caffe\n",
    "import os\n",
    "os.chdir('/home/mckc/image class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L, params as P\n",
    "\n",
    "def lenet(data_location, batch_size):\n",
    "    # our version of LeNet: a series of linear and simple nonlinear transformations\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    n.data, n.label = L.ImageData(batch_size=batch_size,  source=data_location,\n",
    "                             transform_param=(dict(scale=1./255,mirror=True,crop_size= 224)), ntop=2)\n",
    "    \n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.conv2 = L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))\n",
    "    n.pool2 = L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.fc1 =   L.InnerProduct(n.pool2, num_output=500, weight_filler=dict(type='xavier'))\n",
    "    n.relu1 = L.ReLU(n.fc1, in_place=True)\n",
    "    n.score = L.InnerProduct(n.relu1, num_output=2, weight_filler=dict(type='xavier'))\n",
    "    n.loss =  L.SoftmaxWithLoss(n.score, n.label)\n",
    "    \n",
    "    return n.to_proto()\n",
    "    \n",
    "with open('lenet_auto_train.prototxt', 'w') as f:\n",
    "    f.write(str(lenet('caffe_train.txt', 2)))\n",
    "    \n",
    "with open('lenet_auto_test.prototxt', 'w') as f:\n",
    "    f.write(str(lenet('caffe_validate.txt', 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\r\n",
      "  name: \"data\"\r\n",
      "  type: \"ImageData\"\r\n",
      "  top: \"data\"\r\n",
      "  top: \"label\"\r\n",
      "  transform_param {\r\n",
      "    scale: 0.00392156862745\r\n",
      "    mirror: true\r\n",
      "    crop_size: 224\r\n",
      "  }\r\n",
      "  image_data_param {\r\n",
      "    source: \"caffe_train.txt\"\r\n",
      "    batch_size: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv1\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"data\"\r\n",
      "  top: \"conv1\"\r\n",
      "  convolution_param {\r\n",
      "    num_output: 20\r\n",
      "    kernel_size: 5\r\n",
      "    weight_filler {\r\n",
      "      type: \"xavier\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"pool1\"\r\n",
      "  type: \"Pooling\"\r\n",
      "  bottom: \"conv1\"\r\n",
      "  top: \"pool1\"\r\n",
      "  pooling_param {\r\n",
      "    pool: MAX\r\n",
      "    kernel_size: 2\r\n",
      "    stride: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv2\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"pool1\"\r\n",
      "  top: \"conv2\"\r\n",
      "  convolution_param {\r\n",
      "    num_output: 50\r\n",
      "    kernel_size: 5\r\n",
      "    weight_filler {\r\n",
      "      type: \"xavier\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"pool2\"\r\n",
      "  type: \"Pooling\"\r\n",
      "  bottom: \"conv2\"\r\n",
      "  top: \"pool2\"\r\n",
      "  pooling_param {\r\n",
      "    pool: MAX\r\n",
      "    kernel_size: 2\r\n",
      "    stride: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"fc1\"\r\n",
      "  type: \"InnerProduct\"\r\n",
      "  bottom: \"pool2\"\r\n",
      "  top: \"fc1\"\r\n",
      "  inner_product_param {\r\n",
      "    num_output: 500\r\n",
      "    weight_filler {\r\n",
      "      type: \"xavier\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu1\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"fc1\"\r\n",
      "  top: \"fc1\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"score\"\r\n",
      "  type: \"InnerProduct\"\r\n",
      "  bottom: \"fc1\"\r\n",
      "  top: \"score\"\r\n",
      "  inner_product_param {\r\n",
      "    num_output: 2\r\n",
      "    weight_filler {\r\n",
      "      type: \"xavier\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"loss\"\r\n",
      "  type: \"SoftmaxWithLoss\"\r\n",
      "  bottom: \"score\"\r\n",
      "  bottom: \"label\"\r\n",
      "  top: \"loss\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat lenet_auto_train.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The train/test net protocol buffer definition\r\n",
      "train_net: \"lenet_auto_train.prototxt\"\r\n",
      "test_net: \"lenet_auto_test.prototxt\"\r\n",
      "# test_iter specifies how many forward passes the test should carry out.\r\n",
      "# In the case of MNIST, we have test batch size 100 and 100 test iterations,\r\n",
      "# covering the full 10,000 testing images.\r\n",
      "test_iter: 100\r\n",
      "# Carry out testing every 500 training iterations.\r\n",
      "test_interval: 50\r\n",
      "# The base learning rate, momentum and the weight decay of the network.\r\n",
      "base_lr: 0.01\r\n",
      "momentum: 0.9\r\n",
      "weight_decay: 0.0005\r\n",
      "# The learning rate policy\r\n",
      "lr_policy: \"inv\"\r\n",
      "gamma: 0.0001\r\n",
      "power: 0.75\r\n",
      "# Display every 100 iterations\r\n",
      "display: 100\r\n",
      "# The maximum number of iterations\r\n",
      "max_iter: 1000\r\n",
      "# snapshot intermediate results\r\n",
      "snapshot: 50\r\n",
      "snapshot_prefix: \"lenet\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat lenet_auto_solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "### load the solver and create train and test nets\n",
    "solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "solver = caffe.SGDSolver('lenet_auto_solver.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', (2, 3, 224, 224)),\n",
       " ('label', (2,)),\n",
       " ('conv1', (2, 20, 220, 220)),\n",
       " ('pool1', (2, 20, 110, 110)),\n",
       " ('conv2', (2, 50, 106, 106)),\n",
       " ('pool2', (2, 50, 53, 53)),\n",
       " ('fc1', (2, 500)),\n",
       " ('score', (2, 2)),\n",
       " ('loss', ())]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each output is (batch size, feature dim, spatial dim)\n",
    "[(k, v.data.shape) for k, v in solver.net.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1', (20, 3, 5, 5)),\n",
       " ('conv2', (50, 20, 5, 5)),\n",
       " ('fc1', (500, 140450)),\n",
       " ('score', (2, 500))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just print the weight sizes (we'll omit the biases)\n",
    "[(k, v[0].data.shape) for k, v in solver.net.params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': array(0.7147831320762634, dtype=float32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.net.forward()  # train net\n",
    "solver.test_nets[0].forward()  # test net (there can be more than one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imshow(solver.net.params['conv1'][0].diff[:, 0].reshape(4, 5, 5, 5)\n",
    "       .transpose(0, 2, 1, 3).reshape(4*5, 5*5), cmap='gray'); axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
