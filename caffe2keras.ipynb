{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Quadro M2000M (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "# Import Keras Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "import caffe\n",
    "import caffe.io\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import Preprocessing Libaries\n",
    "import karpathy_preprocess\n",
    "\n",
    "# Import Keras Models\n",
    "import keras_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the parameters from Caffe, returned in the variable \"params\"\n",
    "def get_caffe_params( netname, paramname ):\n",
    "    net = caffe.Net(netname, paramname, caffe.TEST)\n",
    "    params = collections.OrderedDict()\n",
    "  \n",
    "  # Read all the parameters into numpy arrays\n",
    "    for layername in net.params:\n",
    "        caffelayer = net.params[layername]\n",
    "        params[layername] = []\n",
    "        for sublayer in caffelayer:\n",
    "            params[layername].append( sublayer.data ) \n",
    "        print \"layer \"+layername+\" has \"+str(len(caffelayer))+\" sublayers, shape \"+str(params[layername][0].shape)\n",
    "\n",
    "    return params, net\n",
    "\n",
    "# A lot of this is taken from Andrej Karpathy's code. Please reference him if you reference us!\n",
    "def read_image_list( image_list , image_dims=(256,256), crop_dims=(227,227) ):\n",
    "    input_images = []\n",
    "    for IMAGE_FILE in open(image_list,'r').read().split():\n",
    "        input_images.append( caffe.io.resize_image( caffe.io.load_image(IMAGE_FILE), (256,256) ))\n",
    "\n",
    "# Scale to standardize input dimensions.\n",
    "    input_ = np.zeros((len(input_images),\n",
    "                     image_dims[0],\n",
    "                     image_dims[1],\n",
    "                     input_images[0].shape[2]),\n",
    "                    dtype=np.float32)\n",
    "    for ix, in_ in enumerate(input_images):\n",
    "        input_[ix] = caffe.io.resize_image(in_, image_dims)\n",
    "    \n",
    "    if oversample:\n",
    "    # Generate center, corner, and mirrored crops.\n",
    "        input_ = caffe.io.oversample(input_, crop_dims)\n",
    "    else:\n",
    "    # Take center crop.\n",
    "        center = np.array(self.image_dims) / 2.0\n",
    "        crop = np.tile(center, (1, 2))[0] + np.concatenate([\n",
    "        -self.crop_dims / 2.0,\n",
    "         self.crop_dims / 2.0\n",
    "         ])\n",
    "        input_ = input_[:, crop[0]:crop[2], crop[1]:crop[3], :]\n",
    "\n",
    "# Classify\n",
    "    caffe_in = np.zeros(np.array(input_.shape)[[0, 3, 1, 2]],\n",
    "                      dtype=np.float32)\n",
    "    for ix, in_ in enumerate(input_):\n",
    "        caffe_in[ix] = self.transformer.preprocess(self.inputs[0], in_)\n",
    "    \n",
    "    return images\n",
    "\n",
    "########### FUNCTIONALITY FROM KERAS ###########\n",
    "\n",
    "# KERAS\n",
    "def set_keras_params( model, params ):\n",
    "\n",
    "    weightlayers=[]\n",
    "    layerindex = 0\n",
    "    for layer in model.layers:\n",
    "        if len(layer.get_weights()) > 0:\n",
    "            weightlayers.append(layerindex)\n",
    "        layerindex+=1\n",
    "    print \"There are \"+str(len(weightlayers))+\" layers in the model with weights\"\n",
    "\n",
    "    if len(weightlayers) != len(params):\n",
    "        print \"ERROR: caffe model and specified keras model do not match\"\n",
    "    return model \n",
    "\n",
    "    paramkeys = params.keys()\n",
    "\n",
    "    for i in xrange(0,len(params)):\n",
    "        layer = model.layers[ weightlayers[i] ]\n",
    "        weights = params[paramkeys[i]]\n",
    "\n",
    "    # Dense layers are specified as Input-Output in Keras\n",
    "        if type(layer) is Dense:\n",
    "            weights[0] = weights[0].transpose(1,0)\n",
    "            weights[1] = weights[1]\n",
    "    # Convolution 2D is specified as flip and then multiply\n",
    "        elif type(layer) is Convolution2D:\n",
    "            weights[0] = weights[0].transpose(0,1,2,3)[:,:,::-1,::-1]\n",
    "        layer.set_weights( weights )\n",
    "    \n",
    "    return model\n",
    "def set_keras_partial( model, params ):\n",
    "\n",
    "    weightlayers=[]\n",
    "    layerindex = 0\n",
    "    for layer in model.layers:\n",
    "        if len(layer.get_weights()) > 0:\n",
    "            weightlayers.append(layerindex)\n",
    "        layerindex+=1\n",
    "    print \"There are \"+str(len(weightlayers))+\" layers in the model with weights\"\n",
    "\n",
    "    paramkeys = params.keys()\n",
    "\n",
    "    for i in xrange(0,len(params)):\n",
    "        if i > (len(weightlayers)-1):\n",
    "            break\n",
    "        layer = model.layers[ weightlayers[i] ]\n",
    "        weights = params[paramkeys[i]]\n",
    "        if type(layer) is Dense:\n",
    "            weights[0] = weights[0].transpose(1,0)\n",
    "            weights[1] = weights[1]\n",
    "        else:\n",
    "            weights[0] = weights[0].transpose(0,1,2,3)[:,:,::-1,::-1]\n",
    "        layer.set_weights( weights )\n",
    "        print \"Finished caffe(\"+str(i)+ \" corresponding to keras layer \"+str(weightlayers[i] )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Transfer caffe network to keras\n",
    "def caffe2keras( caffemodel, caffeparams, kerasmodel ):\n",
    "\n",
    "    params,net = get_caffe_params( caffemodel, caffeparams )\n",
    "    kerasmodel = set_keras_params(kerasmodel, params)\n",
    "    kerasmodel.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "\n",
    "    print \"Finished compiling categoral crossentropy on VGG network.\"\n",
    "\n",
    "    return kerasmodel,net\n",
    "\n",
    "\n",
    "# Transfer caffe network to keras\n",
    "def caffe2keras_partial( caffemodel, caffeparams, kerasmodel ):\n",
    "\n",
    "    params,net = get_caffe_params( caffemodel, caffeparams )\n",
    "    kerasmodel = set_keras_partial(kerasmodel, params)\n",
    "    kerasmodel.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "\n",
    "    print \"Finished compiling categoral crossentropy on VGG network.\"\n",
    "\n",
    "    return kerasmodel,net\n",
    " \n",
    "# VGG Net 16 Layers\n",
    "def transfer_vgg():\n",
    "   \n",
    "    import keras_vgg\n",
    "    netname='/home/mckc/Downloads/vgg_face_caffe/VGG_FACE_deploy.prototxt'\n",
    "    paramname='/home/mckc/Downloads/vgg_face_caffe/VGG_FACE.caffemodel'\n",
    "  \n",
    "    params,net = get_caffe_params( netname, paramname )\n",
    "    #reload(keras_vgg)\n",
    "    model = keras_vgg.vggmodel()\n",
    "    model = set_keras_params(model, params)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "\n",
    "    print \"Finished compiling categoral crossentropy on VGG network.\"\n",
    "\n",
    "    return model,net\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer conv1_1 has 2 sublayers, shape (64, 3, 3, 3)\n",
      "layer conv1_2 has 2 sublayers, shape (64, 64, 3, 3)\n",
      "layer conv2_1 has 2 sublayers, shape (128, 64, 3, 3)\n",
      "layer conv2_2 has 2 sublayers, shape (128, 128, 3, 3)\n",
      "layer conv3_1 has 2 sublayers, shape (256, 128, 3, 3)\n",
      "layer conv3_2 has 2 sublayers, shape (256, 256, 3, 3)\n",
      "layer conv3_3 has 2 sublayers, shape (256, 256, 3, 3)\n",
      "layer conv4_1 has 2 sublayers, shape (512, 256, 3, 3)\n",
      "layer conv4_2 has 2 sublayers, shape (512, 512, 3, 3)\n",
      "layer conv4_3 has 2 sublayers, shape (512, 512, 3, 3)\n",
      "layer conv5_1 has 2 sublayers, shape (512, 512, 3, 3)\n",
      "layer conv5_2 has 2 sublayers, shape (512, 512, 3, 3)\n",
      "layer conv5_3 has 2 sublayers, shape (512, 512, 3, 3)\n",
      "layer fc6 has 2 sublayers, shape (4096, 25088)\n",
      "layer fc7 has 2 sublayers, shape (4096, 4096)\n",
      "layer fc8 has 2 sublayers, shape (2622, 4096)\n",
      "There are 16 layers in the model with weights\n",
      "Finished compiling categoral crossentropy on VGG network.\n"
     ]
    }
   ],
   "source": [
    "model,net = transfer_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('/home/mckc/Face_code/face.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
