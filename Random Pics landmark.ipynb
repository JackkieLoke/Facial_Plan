{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import dlib\n",
    "import openface\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "predictor_model = \"/home/mckc/Downloads/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the image data into numpy\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[:,:,:], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_landmarks(im,i):\n",
    "    predictor_model = \"/home/mckc/Downloads/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(predictor_model)\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) > 1:\n",
    "        print 'TooManyFaces',i\n",
    "        return None\n",
    "    if len(rects) == 0:\n",
    "        print 'NoFaces',i\n",
    "        return None\n",
    "    coords = np.array([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "    centroid = coords.mean(axis=0)\n",
    "    return ((coords - centroid )).reshape(1,136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from termcolor import colored\n",
    "    \n",
    "    train = pd.read_csv('/home/mckc/image class//train.csv')\n",
    "    test = pd.read_csv('/home/mckc/image class//test.csv')\n",
    "    print 'the training data shape is ',train.shape\n",
    "    print 'the test data shape is ', test.shape\n",
    "    \n",
    "    X_tr = np.zeros((1,136),dtype=np.uint8)\n",
    "    Y_tr=[]\n",
    "    for i in range(train.shape[0]):\n",
    "        image = np.array(Image.open(train.values[i,0]))\n",
    "        landmarks = get_landmarks(image,train.values[i,0])\n",
    "        if landmarks is not None:\n",
    "            X_tr =  np.vstack((X_tr,landmarks))\n",
    "            Y_tr = np.append(Y_tr,train.values[i,1])\n",
    "        if i % 50==0:\n",
    "            print colored((float(i)/train.shape[0]*100 ,' Percentage complete'), 'green')\n",
    "    \n",
    "    X_tr = X_tr[1:,:]\n",
    "    X_ts = np.zeros((1,136),dtype=np.uint8)\n",
    "    Y_ts=[]\n",
    "    \n",
    "    for i in range(test.shape[0]):\n",
    "        image = np.array(Image.open(test.values[i,0]))\n",
    "        landmarks = get_landmarks(image,test.values[i,0])\n",
    "        if landmarks is not None:\n",
    "            X_ts =  np.vstack((X_ts,landmarks))\n",
    "            Y_ts = np.append(Y_ts,test.values[i,1])\n",
    "            \n",
    "        if i % 50==0:\n",
    "            print colored((float(i)/test.shape[0]*100 ,' Percentage complete'), 'green')\n",
    "    X_ts = X_ts[1:,:]\n",
    "    \n",
    "    print 'the training file shape',X_tr.shape,Y_tr.shape\n",
    "    print 'the testing file shape',X_ts.shape,Y_ts.shape\n",
    "    \n",
    "    return X_tr,X_ts,Y_tr,Y_ts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training data shape is  (114, 2)\n",
      "the test data shape is  (38, 2)\n",
      "\u001b[32m(0.0, ' Percentage complete')\u001b[0m\n",
      "NoFaces /home/mckc/image class/Mahati_20.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_14.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_112.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_13.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_72.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_75.jpg\n",
      "TooManyFaces /home/mckc/image class/Nivetha_42.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_11.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_26.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_33.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_51.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_34.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_9.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_41.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_96.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_1.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_82.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_109.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_40.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_81.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_32.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_65.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_12.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_34.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_106.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_45.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_3.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_7.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_102.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_25.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_43.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_42.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_60.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_21.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_80.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_44.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_23.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_111.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_25.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_23.jpg\n",
      "\u001b[32m(43.859649122807014, ' Percentage complete')\u001b[0m\n",
      "NoFaces /home/mckc/image class/Mahati_59.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_45.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_2.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_66.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_5.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_79.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_93.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_53.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_5.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_69.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_35.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_8.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_62.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_18.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_30.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_10.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_105.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_67.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_11.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_57.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_108.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_78.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_61.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_32.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_17.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_15.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_22.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_21.jpg\n",
      "TooManyFaces /home/mckc/image class/Nivetha_41.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_89.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_0.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_56.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_48.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_64.jpg\n",
      "\u001b[32m(87.71929824561403, ' Percentage complete')\u001b[0m\n",
      "NoFaces /home/mckc/image class/Nivetha_43.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_70.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_88.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_37.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_97.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_68.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_55.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_83.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_46.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_36.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_0.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_86.jpg\n",
      "\u001b[32m(0.0, ' Percentage complete')\u001b[0m\n",
      "NoFaces /home/mckc/image class/Mahati_107.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_87.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_30.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_28.jpg\n",
      "TooManyFaces /home/mckc/image class/Nivetha_37.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_15.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_4.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_95.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_7.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_52.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_77.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_103.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_6.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_99.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_14.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_104.jpg\n",
      "TooManyFaces /home/mckc/image class/Mahati_91.jpg\n",
      "TooManyFaces /home/mckc/image class/Nivetha_16.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_18.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_73.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_16.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_19.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_54.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_31.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_92.jpg\n",
      "NoFaces /home/mckc/image class/Nivetha_1.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_19.jpg\n",
      "NoFaces /home/mckc/image class/Mahati_58.jpg\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/mckc/image class/Mahati_50.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7a0087c8fa35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_tst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_tst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-edf131d688e7>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mlandmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_landmarks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mckc/anaconda/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2256\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2258\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/mckc/image class/Mahati_50.jpg'"
     ]
    }
   ],
   "source": [
    "X_tr,X_tst,Y_tr,Y_tst = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map, Y_number = np.unique(Y_tr, return_inverse=True)\n",
    "Y_test_number = np.unique(Y_tst, return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(verbose=0,n_jobs=-1,multi_class='multinomial',solver='lbfgs',max_iter=500,warm_start=True)\n",
    "clf.fit(X_tr,Y_number)\n",
    "Y_logictic= clf.predict(X_tst)\n",
    "Y_log_vales = map[Y_logictic]\n",
    "\n",
    "print 'Accuracy of the model is ',accuracy_score(Y_tst,Y_log_vales)\n",
    "confusion_matrix(Y_tst,Y_log_vales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "recognizer = RandomForestClassifier(500,verbose=0,oob_score=True,n_jobs=-1,max_features=20)\n",
    "recognizer.fit(X_tr,Y_number)\n",
    "Y_rf= recognizer.predict(X_tst)\n",
    "Y_rf_vales = map[Y_rf]\n",
    "\n",
    "print 'Accuracy of the model is ',accuracy_score(Y_tst,Y_rf_vales)\n",
    "confusion_matrix(Y_tst,Y_rf_vales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,LSTM\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "from keras.layers import Merge\n",
    "\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Dense(1000, input_dim=136,activation='relu'))\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Dense(50, input_dim=136,activation='sigmoid'))\n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat')\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(merged)\n",
    "final_model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "final_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'],lr=0.0001)\n",
    "final_model.fit([X_tr,X_tr], Y_Keras,nb_epoch=100, batch_size=1,verbose=1,\n",
    "          validation_split=0.2, callbacks=[early_stopping])\n",
    "y_keras = map[final_model.predict_classes([X_tst,X_tst])]\n",
    "\n",
    "print '/n Accuracy of the model is ',accuracy_score(Y_tst,y_keras)\n",
    "confusion_matrix(Y_tst,y_keras)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
